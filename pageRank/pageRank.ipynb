{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set global file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global filename\n",
    "#filename = \"G1\"\n",
    "#N = 1000\n",
    "filename = \"G2\"\n",
    "N = 237\n",
    "d = 0.85\n",
    "\n",
    "#set iteration count as 5 for task3.2; in other situation iter_count should be 100000\n",
    "iter_count = 100000\n",
    "#iter_count = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of sources:\n",
      "12\n",
      "the number of sinks:\n",
      "8\n",
      "Maximum of in-degree:\n",
      "126\n",
      "Maximum of out-degree:\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "#prepare nodes for algorithm\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "import operator\n",
    "\n",
    "#all the url sets\n",
    "pages = set()\n",
    "#all the url with no out-links\n",
    "sinkset = set()\n",
    "#all the url with no in-links\n",
    "sources = set()\n",
    "#all the edges of url graph\n",
    "edges = []\n",
    "\n",
    "#inlink dict of all url nodes\n",
    "inlink = defaultdict(list)\n",
    "\n",
    "\n",
    "with open(filename+\".txt\", \"r\",encoding=\"utf-8\",newline='\\n') as infile:\n",
    "    for line in infile:\n",
    "        nodes = line.split()\n",
    "        #print(len(nodes))\n",
    "        edge_dict = {}\n",
    "        p = nodes[0]\n",
    "        inlink[p] = []\n",
    "        for i in range(1,len(nodes)):\n",
    "            edge_dict[nodes[i]]=nodes[0]\n",
    "            inlink[p].append(nodes[i])\n",
    "        #print(edge_dict)\n",
    "        #print(inlink[p])\n",
    "        edges.append(edge_dict)\n",
    "            \n",
    "          \n",
    "        for node in nodes:\n",
    "            if node not in pages:\n",
    "                if \",\" in node:\n",
    "                    node = node.replace(\",\",\"\")\n",
    "                pages.add(node)\n",
    "\n",
    "#print(edges)\n",
    "#print(\"inlink:\")\n",
    "#print(inlink)\n",
    "                \n",
    "number_inlink = dict()\n",
    "number_outlink = dict()\n",
    "outlink = defaultdict(list)\n",
    "\n",
    "\n",
    "\n",
    "for p in pages:\n",
    "    #get page without in-link\n",
    "    number_inlink[p] = len(inlink[p])\n",
    "    if number_inlink[p] == 0:\n",
    "        sources |= {p}\n",
    "    #get out-link    \n",
    "    outlink[p] = []\n",
    "    for edge_set in edges:\n",
    "        if p in list(edge_set.keys()):\n",
    "            outlink[p].append(edge_set[p])\n",
    "    number_outlink[p] = len(outlink[p])\n",
    "    if number_outlink[p] == 0:\n",
    "        sinkset |= {p}\n",
    "\n",
    "#sorted nodes by in-degree        \n",
    "sorted_inlink_count = OrderedDict(sorted(number_inlink.items(), key=lambda kv: kv[1],reverse=True))\n",
    "#print(\"sorted_inlink_count\")\n",
    "#print(sorted_inlink_count)\n",
    "save_name = filename + \"sortedByinlink.txt\"\n",
    "f = open(save_name,\"a+\",encoding=\"utf-8\",newline='\\n')\n",
    "for sort_link in sorted_inlink_count.items(): \n",
    "    #print(sort_link)\n",
    "    message = sort_link[0] + \" \" + str(sort_link[1]) + '\\n' \n",
    "    f.write(message)\n",
    "f.close()\n",
    "\n",
    "\n",
    "#sorted nodes by out-degree        \n",
    "sorted_outlink_count = OrderedDict(sorted(number_outlink.items(), key=lambda kv: kv[1],reverse=True))\n",
    "#print(\"sorted_outlink_count\")\n",
    "#print(sorted_outlink_count)\n",
    "\n",
    "#print(\"outlink:\")\n",
    "#print(outlink)            \n",
    "#print(\"number_outlink:\")\n",
    "#print(number_outlink)    \n",
    "#print(\"sinkset:\")\n",
    "#print(sinkset)  \n",
    "maximum_in =  str(next(iter(sorted_inlink_count.items()))[1])\n",
    "maximum_out = str(next(iter(sorted_outlink_count.items()))[1])\n",
    "print(\"the number of sources:\")\n",
    "print(str(len(sources)))\n",
    "print(\"the number of sinks:\")\n",
    "print(str(len(sinkset)))\n",
    "print(\"Maximum of in-degree:\") \n",
    "print(maximum_in)    \n",
    "print(\"Maximum of out-degree:\")\n",
    "print(maximum_out)\n",
    "\n",
    "save_name = filename+\"statistics.txt\"\n",
    "f = open(save_name,\"a+\",encoding=\"utf-8\",newline='\\n')\n",
    "message = \"the number of sources:\" + str(len(sources)) + '\\n' \n",
    "message += \"The number of sinks:\" + str(len(sinkset)) + '\\n' \n",
    "message += \"Maximum of in-degree:\" + maximum_in + '\\n'\n",
    "message += \"Maximum of out-degree:\" + maximum_out\n",
    "f.write(message)\n",
    "f.close()\n",
    "\n",
    "\n",
    "#set inlink(p)\n",
    "#inlink[p]\n",
    "#set outlink(q)\n",
    "#outlink[q]    \n",
    "#set number_outlink\n",
    "#number_outlink[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get L1-norm value\n",
    "\"\"\"\n",
    "def L1_nomal(newPR,PR):\n",
    "    sum_l1 = 0.0\n",
    "    for page in pages:\n",
    "        sum_l1 += abs(newPR[page] - PR[page])\n",
    "    return sum_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank score has converged!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "url_docId = dict()\n",
    "with open(\"docIdmap.txt\", \"r\",encoding=\"utf-8\",newline='\\n') as infile1:\n",
    "    for line in infile1:\n",
    "        nodes = line.split(\",\")\n",
    "        nodes[1] = nodes[1].rstrip()\n",
    "        url_docId[nodes[0]] = nodes[1]\n",
    "#print(url_docId)        \n",
    "PR = dict()\n",
    "newPR = dict()\n",
    "converge = 0;\n",
    "itera = 0;\n",
    "\n",
    "for page in pages:\n",
    "    PR[page] = 1.0/N    #initial value\n",
    "\n",
    "while True:\n",
    "    sinkPR = 0\n",
    "    itera += 1;\n",
    "    for sink in sinkset:\n",
    "        sinkPR += PR[sink]\n",
    "    for p in pages:\n",
    "        newPR[p] = (1-d)/N\n",
    "        newPR[p] += d*sinkPR/N\n",
    "        for q in inlink[p]:\n",
    "            newPR[p] += d*PR[q]/number_outlink[q]\n",
    "    score = L1_nomal(newPR,PR)\n",
    "    save_name = filename+\"by\"+str(d)+\"iteration.txt\"\n",
    "    f = open(save_name,\"a+\",encoding=\"utf-8\",newline='\\n')\n",
    "    sorted_PR_by_value = sorted(PR.items(), key=lambda kv: kv[1],reverse=True)\n",
    "    sorted_NewPR_by_value = sorted(newPR.items(), key=lambda kv: kv[1],reverse=True)\n",
    "    message = \"The \"+str(itera)+\" iterations:\" +\"score \"+ str(score) + '\\n' + str(sorted_NewPR_by_value) + '\\n' + str(sorted_PR_by_value)+'\\n'\n",
    "    f.write(message)\n",
    "    f.close()\n",
    "    \n",
    "    sum_pr = 0.0\n",
    "    for page in pages:\n",
    "        sum_pr += newPR[page]\n",
    "    save_name = \"L1_nomby\"+str(d)+\".txt\"\n",
    "    f = open(save_name,\"a+\",encoding=\"utf-8\",newline='\\n')\n",
    "    message = filename + \": \" + str(itera) + \" iteration\" + '\\n' + \"L1-norm: \"+ str(score) + \" newPR sum: \" + str(sum_pr) + '\\n'\n",
    "    f.write(message)\n",
    "    f.close()\n",
    "    \n",
    "    #print(\"The \"+str(itera)+\" iterations:\")\n",
    "    #print(newPR)\n",
    "    #print(PR)\n",
    "    #print(score)\n",
    "    if itera > iter_count:\n",
    "        print(\"Iterating greater than the global setting. Stop computing now! If wrong, please check the global setting\")\n",
    "        for pr in sorted_NewPR_by_value:\n",
    "            save_name = filename+\"pagerank4Timesby\"+str(d)+\".txt\"\n",
    "            f = open(save_name,\"a+\",encoding=\"utf-8\",newline='\\n')\n",
    "            message = pr[0]+\" \"+str(pr[1]) + \"\\n\"\n",
    "            f.write(pr[0]+\" \"+str(pr[1]) + \"\\n\")\n",
    "            f.close() \n",
    "        break\n",
    "    elif score > 0.001:\n",
    "        for p in pages:\n",
    "            PR[p] =  newPR[p]\n",
    "        continue\n",
    "    elif converge < 5:\n",
    "        for p in pages:\n",
    "            PR[p] =  newPR[p]\n",
    "        converge +=1\n",
    "        continue\n",
    "    else:\n",
    "        print(\"PageRank score has converged!\")\n",
    "        top50 = 1\n",
    "        for pr in sorted_NewPR_by_value:\n",
    "            save_name = filename+\"pagerankby\"+str(d)+\".txt\"\n",
    "            f = open(save_name,\"a+\",encoding=\"utf-8\",newline='\\n')\n",
    "            message = pr[0]+\" \"+str(pr[1]) + \"\\n\"\n",
    "            f.write(message)\n",
    "            f.close() \n",
    "            if(filename == \"G1\"):\n",
    "                try:\n",
    "                    save_name = filename+\"urlPageRankBy\"+str(d)+\".txt\"\n",
    "                    f = open(save_name,\"a+\",encoding=\"utf-8\",newline='\\n')\n",
    "                    message = url_docId[pr[0]]+\" \"+str(pr[1]) + \"\\n\"\n",
    "                    f.write(message)\n",
    "                    f.close() \n",
    "                except KeyError:\n",
    "                    continue\n",
    "            if(filename == \"G2\"):\n",
    "                try:\n",
    "                    save_name = filename+\"urlPageRankBy\"+str(d)+\".txt\"\n",
    "                    f = open(save_name,\"a+\",encoding=\"utf-8\",newline='\\n')\n",
    "                    message = \"https://en.wikipedia.org/wiki/\" + str(pr[0]) +\" \"+str(pr[1]) + \"\\n\"\n",
    "                    f.write(message)\n",
    "                    f.close() \n",
    "                except KeyError:\n",
    "                    continue\n",
    "            if top50 < 51:\n",
    "                save_name = filename+\"pagerankTop50by\"+str(d)+\".txt\"\n",
    "                f = open(save_name,\"a+\",encoding=\"utf-8\",newline='\\n')\n",
    "                message = pr[0]+\" \"+str(pr[1]) + \"\\n\"\n",
    "                f.write(pr[0]+\" \"+str(pr[1]) + \"\\n\")\n",
    "                f.close()\n",
    "                top50 += 1\n",
    "            #print(pr)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demo test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank score has converged!\n",
      "('D', 0.11890595625353888)\n",
      "('B', 0.1393075828066674)\n",
      "('C', 0.1513076495622817)\n",
      "('F', 0.1513076495622817)\n",
      "('E', 0.1870434366372427)\n",
      "('A', 0.2521277251779877)\n"
     ]
    }
   ],
   "source": [
    "N = 6\n",
    "PR = dict()\n",
    "newPR = dict()\n",
    "converge = 0;\n",
    "d = 0.85\n",
    "itera = 0;\n",
    "\n",
    "for page in pages:\n",
    "    PR[page] = 1.0/N    #initial value\n",
    "\n",
    "while True:\n",
    "    sinkPR = 0\n",
    "    itera += 1;\n",
    "    for sink in sinkset:\n",
    "        sinkPR += PR[sink]\n",
    "    for p in pages:\n",
    "        newPR[p] = (1-d)/N\n",
    "        newPR[p] += d*sinkPR/N\n",
    "        for q in inlink[p]:\n",
    "            newPR[p] += d*PR[q]/number_outlink[q]\n",
    "    score = L1_nomal(newPR,PR)\n",
    "    f = open(\"iteration.txt\",\"a+\",encoding=\"utf-8\",newline='\\n')\n",
    "    sorted_PR_by_value = sorted(PR.items(), key=lambda kv: kv[1])\n",
    "    sorted_NewPR_by_value = sorted(newPR.items(), key=lambda kv: kv[1])\n",
    "    message = \"The \"+str(itera)+\" iterations:\" +\"score \"+ str(score) + '\\n' + str(sorted_NewPR_by_value) + '\\n' + str(sorted_PR_by_value)+'\\n'\n",
    "    f.write(message)\n",
    "    f.close()\n",
    "    #print(\"The \"+str(itera)+\" iterations:\")\n",
    "    #print(newPR)\n",
    "    #print(PR)\n",
    "    #print(score)\n",
    "    if score > 0.001:\n",
    "        for p in pages:\n",
    "            PR[p] =  newPR[p]\n",
    "        continue\n",
    "    elif converge < 5:\n",
    "        for p in pages:\n",
    "            PR[p] =  newPR[p]\n",
    "        converge +=1\n",
    "        continue\n",
    "    else:\n",
    "        print(\"PageRank score has converged!\")\n",
    "        for pr in sorted_NewPR_by_value:\n",
    "            print(pr)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\n",
    "sorted_by_value = sorted(x.items(), key=lambda kv: kv[1])\n",
    "print(sorted_by_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple, banana\n"
     ]
    }
   ],
   "source": [
    "txt = \"apple, banana, cherry\"\n",
    "\n",
    "# setting the max parameter to 1, will return a list with 2 elements!\n",
    "x = txt.rsplit(\", \", 1)[0]\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
